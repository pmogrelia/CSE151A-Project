{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYIJBf74ZduK"
   },
   "source": [
    "# Milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to our [ReadME](README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxDRjzHuaCox"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ociYZrm-aIMy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' not in globals():\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('main.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7062606, 120)\n",
      "\n",
      "Column names:\n",
      "['MI_dir_L5_weight', 'MI_dir_L5_mean', 'MI_dir_L5_variance', 'MI_dir_L3_weight', 'MI_dir_L3_mean', 'MI_dir_L3_variance', 'MI_dir_L1_weight', 'MI_dir_L1_mean', 'MI_dir_L1_variance', 'MI_dir_L0.1_weight', 'MI_dir_L0.1_mean', 'MI_dir_L0.1_variance', 'MI_dir_L0.01_weight', 'MI_dir_L0.01_mean', 'MI_dir_L0.01_variance', 'H_L5_weight', 'H_L5_mean', 'H_L5_variance', 'H_L3_weight', 'H_L3_mean', 'H_L3_variance', 'H_L1_weight', 'H_L1_mean', 'H_L1_variance', 'H_L0.1_weight', 'H_L0.1_mean', 'H_L0.1_variance', 'H_L0.01_weight', 'H_L0.01_mean', 'H_L0.01_variance', 'HH_L5_weight', 'HH_L5_mean', 'HH_L5_std', 'HH_L5_magnitude', 'HH_L5_radius', 'HH_L5_covariance', 'HH_L5_pcc', 'HH_L3_weight', 'HH_L3_mean', 'HH_L3_std', 'HH_L3_magnitude', 'HH_L3_radius', 'HH_L3_covariance', 'HH_L3_pcc', 'HH_L1_weight', 'HH_L1_mean', 'HH_L1_std', 'HH_L1_magnitude', 'HH_L1_radius', 'HH_L1_covariance', 'HH_L1_pcc', 'HH_L0.1_weight', 'HH_L0.1_mean', 'HH_L0.1_std', 'HH_L0.1_magnitude', 'HH_L0.1_radius', 'HH_L0.1_covariance', 'HH_L0.1_pcc', 'HH_L0.01_weight', 'HH_L0.01_mean', 'HH_L0.01_std', 'HH_L0.01_magnitude', 'HH_L0.01_radius', 'HH_L0.01_covariance', 'HH_L0.01_pcc', 'HH_jit_L5_weight', 'HH_jit_L5_mean', 'HH_jit_L5_variance', 'HH_jit_L3_weight', 'HH_jit_L3_mean', 'HH_jit_L3_variance', 'HH_jit_L1_weight', 'HH_jit_L1_mean', 'HH_jit_L1_variance', 'HH_jit_L0.1_weight', 'HH_jit_L0.1_mean', 'HH_jit_L0.1_variance', 'HH_jit_L0.01_weight', 'HH_jit_L0.01_mean', 'HH_jit_L0.01_variance', 'HpHp_L5_weight', 'HpHp_L5_mean', 'HpHp_L5_std', 'HpHp_L5_magnitude', 'HpHp_L5_radius', 'HpHp_L5_covariance', 'HpHp_L5_pcc', 'HpHp_L3_weight', 'HpHp_L3_mean', 'HpHp_L3_std', 'HpHp_L3_magnitude', 'HpHp_L3_radius', 'HpHp_L3_covariance', 'HpHp_L3_pcc', 'HpHp_L1_weight', 'HpHp_L1_mean', 'HpHp_L1_std', 'HpHp_L1_magnitude', 'HpHp_L1_radius', 'HpHp_L1_covariance', 'HpHp_L1_pcc', 'HpHp_L0.1_weight', 'HpHp_L0.1_mean', 'HpHp_L0.1_std', 'HpHp_L0.1_magnitude', 'HpHp_L0.1_radius', 'HpHp_L0.1_covariance', 'HpHp_L0.1_pcc', 'HpHp_L0.01_weight', 'HpHp_L0.01_mean', 'HpHp_L0.01_std', 'HpHp_L0.01_magnitude', 'HpHp_L0.01_radius', 'HpHp_L0.01_covariance', 'HpHp_L0.01_pcc', 'Device', 'is_attack', 'Botnet_Type', 'Attack_Type', 'Label_numeric']\n",
      "\n",
      "First few rows:\n",
      "   MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
      "0          1.000000            60.0                 0.0          1.000000   \n",
      "1          1.000000            60.0                 0.0          1.000000   \n",
      "2          1.000000            60.0                 0.0          1.000000   \n",
      "3          1.000000           590.0                 0.0          1.000000   \n",
      "4          1.927179           590.0                 0.0          1.955648   \n",
      "\n",
      "   MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
      "0            60.0                 0.0          1.000000            60.0   \n",
      "1            60.0                 0.0          1.000000            60.0   \n",
      "2            60.0                 0.0          1.000000            60.0   \n",
      "3           590.0                 0.0          1.000000           590.0   \n",
      "4           590.0                 0.0          1.984992           590.0   \n",
      "\n",
      "   MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.01_std  \\\n",
      "0                 0.0            1.000000  ...    0.000000e+00   \n",
      "1                 0.0            1.000000  ...    9.540000e-07   \n",
      "2                 0.0            1.000000  ...    0.000000e+00   \n",
      "3                 0.0            1.000000  ...    9.199164e+01   \n",
      "4                 0.0            1.998489  ...    1.108120e+02   \n",
      "\n",
      "   HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
      "0             60.000000       0.000000e+00                    0.0   \n",
      "1             60.000000       9.090000e-13                    0.0   \n",
      "2             60.000000       0.000000e+00                    0.0   \n",
      "3            388.850426       8.462461e+03                    0.0   \n",
      "4            418.293119       1.227931e+04                    0.0   \n",
      "\n",
      "   HpHp_L0.01_pcc                                    Device  is_attack  \\\n",
      "0             0.0  SimpleHome_XCS7_1003_WHT_Security_Camera          0   \n",
      "1             0.0  SimpleHome_XCS7_1003_WHT_Security_Camera          0   \n",
      "2             0.0  SimpleHome_XCS7_1003_WHT_Security_Camera          0   \n",
      "3             0.0  SimpleHome_XCS7_1003_WHT_Security_Camera          0   \n",
      "4             0.0  SimpleHome_XCS7_1003_WHT_Security_Camera          0   \n",
      "\n",
      "   Botnet_Type  Attack_Type  Label_numeric  \n",
      "0       Benign       Benign              0  \n",
      "1       Benign       Benign              0  \n",
      "2       Benign       Benign              0  \n",
      "3       Benign       Benign              0  \n",
      "4       Benign       Benign              0  \n",
      "\n",
      "[5 rows x 120 columns]\n",
      "\n",
      "Data types:\n",
      "float64    115\n",
      "object       3\n",
      "int64        2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution:\n",
      "is_attack\n",
      "1    6506674\n",
      "0     555932\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Device distribution:\n",
      "Device\n",
      "Philips_B120N10_Baby_Monitor                1098677\n",
      "Danmini_Doorbell                            1018298\n",
      "SimpleHome_XCS7_1002_WHT_Security_Camera     863056\n",
      "SimpleHome_XCS7_1003_WHT_Security_Camera     850826\n",
      "Provision_PT_838_Security_Camera             836891\n",
      "Ecobee_Thermostat                            835876\n",
      "Provision_PT_737E_Security_Camera            828260\n",
      "Samsung_SNH_1011_N_Webcam                    375222\n",
      "Ennio_Doorbell                               355500\n",
      "Name: count, dtype: int64\n",
      "Device\n",
      "Philips_B120N10_Baby_Monitor                1098677\n",
      "Danmini_Doorbell                            1018298\n",
      "SimpleHome_XCS7_1002_WHT_Security_Camera     863056\n",
      "SimpleHome_XCS7_1003_WHT_Security_Camera     850826\n",
      "Provision_PT_838_Security_Camera             836891\n",
      "Ecobee_Thermostat                            835876\n",
      "Provision_PT_737E_Security_Camera            828260\n",
      "Samsung_SNH_1011_N_Webcam                    375222\n",
      "Ennio_Doorbell                               355500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the dataset structure\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df['is_attack'].value_counts())\n",
    "print(\"\\nDevice distribution:\")\n",
    "print(df['Device'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Following the preprocessing steps outlined in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "0\n",
      "\n",
      "Number of duplicate rows:\n",
      "157779\n",
      "\n",
      "Found 25 weight columns\n",
      "Rows with total weight < 0.001: 0\n",
      "Min total weight: 25.0\n",
      "Max total weight: 252403.3509269681\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values and duplicates\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum().sum())\n",
    "print(\"\\nNumber of duplicate rows:\")\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Check for any rows with minimal weight (close to 0)\n",
    "weight_cols = [col for col in df.columns if 'weight' in col]\n",
    "print(f\"\\nFound {len(weight_cols)} weight columns\")\n",
    "\n",
    "# Check for rows where all weights are very small\n",
    "if weight_cols:\n",
    "    min_weights = df[weight_cols].sum(axis=1)\n",
    "    print(f\"Rows with total weight < 0.001: {(min_weights < 0.001).sum()}\")\n",
    "    print(f\"Min total weight: {min_weights.min()}\")\n",
    "    print(f\"Max total weight: {min_weights.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (7062606, 120)\n",
      "After removing duplicates: (6904827, 120)\n",
      "Removed 157779 duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove duplicates\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "df_clean = df.drop_duplicates()\n",
    "print(f\"After removing duplicates: {df_clean.shape}\")\n",
    "print(f\"Removed {df.shape[0] - df_clean.shape[0]} duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution before balancing:\n",
      "is_attack\n",
      "1    6391327\n",
      "0     513500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalance ratio: 12.45:1\n",
      "\n",
      "Balanced to 513500 samples per class\n",
      "Balanced dataset shape: (1027000, 120)\n",
      "Class distribution after balancing:\n",
      "is_attack\n",
      "0    513500\n",
      "1    513500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Balanced sampling approach\n",
    "print(\"\\nClass distribution before balancing:\")\n",
    "class_counts = df_clean['is_attack'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Calculate class imbalance ratio\n",
    "attack_count = class_counts[1]\n",
    "benign_count = class_counts[0]\n",
    "imbalance_ratio = max(attack_count, benign_count) / min(attack_count, benign_count)\n",
    "\n",
    "print(f\"\\nImbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "# Only balance if significantly imbalanced (>3:1 ratio)\n",
    "if imbalance_ratio > 3.0:\n",
    "    # Use the minority class size as target for both classes\n",
    "    target_size = min(attack_count, benign_count)\n",
    "    \n",
    "    # Sample equal amounts from both classes\n",
    "    benign_data = df_clean[df_clean['is_attack'] == 0].sample(n=target_size, random_state=42)\n",
    "    attack_data = df_clean[df_clean['is_attack'] == 1].sample(n=target_size, random_state=42)\n",
    "    \n",
    "    df_balanced = pd.concat([benign_data, attack_data], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nBalanced to {target_size} samples per class\")\n",
    "    print(f\"Balanced dataset shape: {df_balanced.shape}\")\n",
    "    print(\"Class distribution after balancing:\")\n",
    "    print(df_balanced['is_attack'].value_counts())\n",
    "else:\n",
    "    df_balanced = df_clean.copy()\n",
    "    print(\"Data is reasonably balanced - no sampling needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing 116 numeric columns...\n",
      "\n",
      "Final preprocessed dataset shape: (1027000, 120)\n",
      "\n",
      "Preprocessing complete!\n",
      "\n",
      "Final class distribution:\n",
      "is_attack\n",
      "0    513500\n",
      "1    513500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape: (1027000, 120)\n",
      "\n",
      "Preprocessing complete!\n",
      "\n",
      "Final class distribution:\n",
      "is_attack\n",
      "0    513500\n",
      "1    513500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Simple normalization (min-max scaling)\n",
    "# Only normalize numeric feature columns, preserve categorical\n",
    "numeric_feature_cols = [col for col in df_balanced.columns \n",
    "                       if col not in ['Device', 'is_attack'] and df_balanced[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "print(f\"Normalizing {len(numeric_feature_cols)} numeric columns...\")\n",
    "\n",
    "# Simple min-max scaling (vectorized operation)\n",
    "df_processed = df_balanced.copy()\n",
    "for col in numeric_feature_cols:\n",
    "    col_min = df_processed[col].min()\n",
    "    col_max = df_processed[col].max()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if col_max != col_min:\n",
    "        df_processed[col] = (df_processed[col] - col_min) / (col_max - col_min)\n",
    "    else:\n",
    "        df_processed[col] = 0  # All values are the same\n",
    "\n",
    "print(f\"\\nFinal preprocessed dataset shape: {df_processed.shape}\")\n",
    "print(\"\\nPreprocessing complete!\")\n",
    "print(\"\\nFinal class distribution:\")\n",
    "print(df_processed['is_attack'].value_counts())\n",
    "\n",
    "# Save memory by deleting intermediate dataframes\n",
    "del df_clean, df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing 116 numeric columns...\n",
      "\n",
      "Final preprocessed dataset shape: (7062606, 120)\n",
      "\n",
      "Preprocessing complete!\n",
      "\n",
      "Final class distribution:\n",
      "is_attack\n",
      "1    6506674\n",
      "0     555932\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final preprocessed dataset shape: (7062606, 120)\n",
      "\n",
      "Preprocessing complete!\n",
      "\n",
      "Final class distribution:\n",
      "is_attack\n",
      "1    6506674\n",
      "0     555932\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Simple normalization (min-max scaling)\n",
    "# Only normalize numeric feature columns, preserve categorical\n",
    "numeric_feature_cols = [col for col in df.columns \n",
    "                       if col not in ['Device', 'is_attack'] and df[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "print(f\"Normalizing {len(numeric_feature_cols)} numeric columns...\")\n",
    "\n",
    "# Simple min-max scaling (vectorized operation)\n",
    "df_processed_full = df.copy()\n",
    "for col in numeric_feature_cols:\n",
    "    col_min = df_processed_full[col].min()\n",
    "    col_max = df_processed_full[col].max()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if col_max != col_min:\n",
    "        df_processed_full[col] = (df_processed_full[col] - col_min) / (col_max - col_min)\n",
    "    else:\n",
    "        df_processed_full[col] = 0  # All values are the same\n",
    "\n",
    "print(f\"\\nFinal preprocessed dataset shape: {df_processed_full.shape}\")\n",
    "print(\"\\nPreprocessing complete!\")\n",
    "print(\"\\nFinal class distribution:\")\n",
    "print(df_processed_full['is_attack'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (1027000, 116)\n",
      "Target vector shape: (1027000,)\n",
      "Proper train/test split completed:\n",
      "Train shape: (821600, 116)\n",
      "Test shape: (205400, 116)\n",
      "Train class distribution: is_attack\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Test class distribution: is_attack\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Proper train/test split completed:\n",
      "Train shape: (821600, 116)\n",
      "Test shape: (205400, 116)\n",
      "Train class distribution: is_attack\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Test class distribution: is_attack\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Decision Tree Learning\n",
    "\n",
    "# Prepare features and target\n",
    "X = df_processed.drop(['is_attack', 'Device'], axis=1).select_dtypes(include=[np.number])  # Features only\n",
    "y = df_processed['is_attack']  # Target\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "\n",
    "# Single proper train/test split (80/20) with stratification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_sklearn, X_test_sklearn, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Ensures balanced representation in both sets\n",
    ")\n",
    "\n",
    "print(\"Proper train/test split completed:\")\n",
    "print(f\"Train shape: {X_train_sklearn.shape}\")\n",
    "print(f\"Test shape: {X_test_sklearn.shape}\")\n",
    "print(f\"Train class distribution: {y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Test class distribution: {y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (821600, 116)\n",
      "Test set shape: (205400, 116)\n",
      "TESTING SCORES\n",
      "model accuracy:  0.9994888023369036\n",
      "model precision:  0.9995228496586914\n",
      "model recall:  0.9994547224926972\n",
      "model f1 score:  0.9994887849147732\n",
      "\n",
      " TRAINING SCORES\n",
      "model accuracy:  0.9994559396299902\n",
      "model precision:  0.9994109586040206\n",
      "model recall:  0.9995009737098345\n",
      "model f1 score:  0.9994559641301451\n",
      "\n",
      "Confusion Matrix for TESTING:\n",
      "True Negatives:  102,651\n",
      "False Positives: 49\n",
      "False Negatives: 56\n",
      "True Positives:  102,644\n",
      "TESTING SCORES\n",
      "model accuracy:  0.9994888023369036\n",
      "model precision:  0.9995228496586914\n",
      "model recall:  0.9994547224926972\n",
      "model f1 score:  0.9994887849147732\n",
      "\n",
      " TRAINING SCORES\n",
      "model accuracy:  0.9994559396299902\n",
      "model precision:  0.9994109586040206\n",
      "model recall:  0.9995009737098345\n",
      "model f1 score:  0.9994559641301451\n",
      "\n",
      "Confusion Matrix for TESTING:\n",
      "True Negatives:  102,651\n",
      "False Positives: 49\n",
      "False Negatives: 56\n",
      "True Positives:  102,644\n"
     ]
    }
   ],
   "source": [
    "## Scikit-Learn Decision Tree \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Data is already properly split and numeric from the previous cell\n",
    "print(f\"Training set shape: {X_train_sklearn.shape}\")\n",
    "print(f\"Test set shape: {X_test_sklearn.shape}\")\n",
    "\n",
    "dt_sklearn = DecisionTreeClassifier(\n",
    "    max_depth=6,                    # Tree depth\n",
    "    min_samples_split=1000,         # How many samples are required to split\n",
    "    min_samples_leaf=500,           # Minimum samples per leaf\n",
    "    max_features='sqrt',            # Feature randomization\n",
    "    random_state=42,\n",
    "    class_weight='balanced'         \n",
    ")\n",
    "\n",
    "dt_sklearn.fit(X_train_sklearn, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_sklearn = dt_sklearn.predict(X_test_sklearn)\n",
    "y_pred_train_sklearn = dt_sklearn.predict(X_train_sklearn)\n",
    "\n",
    "# Calculate Test Scores\n",
    "test_accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
    "test_precision = precision_score(y_test, y_pred_sklearn)\n",
    "test_recall = recall_score(y_test, y_pred_sklearn)\n",
    "test_f1 = f1_score(y_test, y_pred_sklearn)\n",
    "\n",
    "# Calculate Training Scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_sklearn)\n",
    "train_precision = precision_score(y_train, y_pred_train_sklearn)\n",
    "train_recall = recall_score(y_train, y_pred_train_sklearn)\n",
    "train_f1 = f1_score(y_train, y_pred_train_sklearn)\n",
    "\n",
    "print(\"TESTING SCORES\")\n",
    "print(\"model accuracy: \", test_accuracy)\n",
    "print(\"model precision: \", test_precision)\n",
    "print(\"model recall: \", test_recall)\n",
    "print(\"model f1 score: \", test_f1)\n",
    "\n",
    "print(\"\\n TRAINING SCORES\")\n",
    "print(\"model accuracy: \", train_accuracy)\n",
    "print(\"model precision: \", train_precision)\n",
    "print(\"model recall: \", train_recall)\n",
    "print(\"model f1 score: \", train_f1)\n",
    "\n",
    "print(\"\\nConfusion Matrix for TESTING:\")\n",
    "cm = confusion_matrix(y_test, y_pred_sklearn)\n",
    "print(f\"True Negatives:  {cm[0,0]:,}\")\n",
    "print(f\"False Positives: {cm[0,1]:,}\")\n",
    "print(f\"False Negatives: {cm[1,0]:,}\")\n",
    "print(f\"True Positives:  {cm[1,1]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the first model on our 7 million instance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (7062606, 117)\n",
      "TESTING SCORES ON 7 MILLION\n",
      "model accuracy:  0.9993775668641292\n",
      "model precision:  0.9998805319694605\n",
      "model recall:  0.9994438018563708\n",
      "model f1 score:  0.9996621192135033\n",
      "\n",
      "Confusion Matrix:\n",
      "TESTING SCORES ON 7 MILLION\n",
      "model accuracy:  0.9993775668641292\n",
      "model precision:  0.9998805319694605\n",
      "model recall:  0.9994438018563708\n",
      "model f1 score:  0.9996621192135033\n",
      "\n",
      "Confusion Matrix:\n",
      "True Negatives:  555,155\n",
      "False Positives: 777\n",
      "False Negatives: 3,619\n",
      "True Positives:  6,503,055\n",
      "True Negatives:  555,155\n",
      "False Positives: 777\n",
      "False Negatives: 3,619\n",
      "True Positives:  6,503,055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numeric_cols = df_processed_full.select_dtypes(include=[np.number]).columns\n",
    "Full_sklearn = df_processed_full[numeric_cols]\n",
    "\n",
    "Full_sklearn_dropped = Full_sklearn.drop(columns=['is_attack'])\n",
    "print(f\"Training set shape: {Full_sklearn.shape}\")\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "y_pred_sklearn = dt_sklearn.predict(Full_sklearn_dropped)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "accuracy = accuracy_score(Full_sklearn['is_attack'], y_pred_sklearn)\n",
    "precision = precision_score(Full_sklearn['is_attack'], y_pred_sklearn)\n",
    "recall = recall_score(Full_sklearn['is_attack'], y_pred_sklearn)\n",
    "f1 = f1_score(Full_sklearn['is_attack'], y_pred_sklearn)\n",
    "\n",
    "print(\"TESTING SCORES ON 7 MILLION\")\n",
    "print(\"model accuracy: \", accuracy)\n",
    "print(\"model precision: \", precision)\n",
    "print(\"model recall: \", recall)\n",
    "print(\"model f1 score: \", f1)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(Full_sklearn['is_attack'], y_pred_sklearn)\n",
    "print(f\"True Negatives:  {cm[0,0]:,}\")\n",
    "print(f\"False Positives: {cm[0,1]:,}\")\n",
    "print(f\"False Negatives: {cm[1,0]:,}\")\n",
    "print(f\"True Positives:  {cm[1,1]:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making second new DTL with new Hyperparameters\n",
    "### (Lower Depth, Higher Minimums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING SCORES\n",
      "model accuracy:  0.9855598831548199\n",
      "model precision:  0.9861184223353024\n",
      "model recall:  0.984985394352483\n",
      "model f1 score:  0.98555158270087\n",
      "\n",
      " TRAINING SCORES\n",
      "model accuracy:  0.9851813534566699\n",
      "model precision:  0.9850172410017058\n",
      "model recall:  0.985350535540409\n",
      "model f1 score:  0.9851838600820942\n",
      "\n",
      "Confusion Matrix for TESTING:\n",
      "True Negatives:  101,276\n",
      "False Positives: 1,424\n",
      "False Negatives: 1,542\n",
      "True Positives:  101,158\n"
     ]
    }
   ],
   "source": [
    "dt_sklearn = DecisionTreeClassifier(\n",
    "    max_depth=3,                    # Tree depth\n",
    "    min_samples_split=10000,         # How many samples are required to split\n",
    "    min_samples_leaf=5000,           # Minimum samples per leaf\n",
    "    max_features='sqrt',            # Feature randomization\n",
    "    random_state=42,\n",
    "    class_weight='balanced'         \n",
    ")\n",
    "\n",
    "dt_sklearn.fit(X_train_sklearn, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_sklearn = dt_sklearn.predict(X_test_sklearn)\n",
    "y_pred_train_sklearn = dt_sklearn.predict(X_train_sklearn)\n",
    "\n",
    "# Calculate Test Scores\n",
    "test_accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
    "test_precision = precision_score(y_test, y_pred_sklearn)\n",
    "test_recall = recall_score(y_test, y_pred_sklearn)\n",
    "test_f1 = f1_score(y_test, y_pred_sklearn)\n",
    "\n",
    "# Calculate Training Scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_sklearn)\n",
    "train_precision = precision_score(y_train, y_pred_train_sklearn)\n",
    "train_recall = recall_score(y_train, y_pred_train_sklearn)\n",
    "train_f1 = f1_score(y_train, y_pred_train_sklearn)\n",
    "\n",
    "print(\"TESTING SCORES\")\n",
    "print(\"model accuracy: \", test_accuracy)\n",
    "print(\"model precision: \", test_precision)\n",
    "print(\"model recall: \", test_recall)\n",
    "print(\"model f1 score: \", test_f1)\n",
    "\n",
    "print(\"\\n TRAINING SCORES\")\n",
    "print(\"model accuracy: \", train_accuracy)\n",
    "print(\"model precision: \", train_precision)\n",
    "print(\"model recall: \", train_recall)\n",
    "print(\"model f1 score: \", train_f1)\n",
    "\n",
    "print(\"\\nConfusion Matrix for TESTING:\")\n",
    "cm = confusion_matrix(y_test, y_pred_sklearn)\n",
    "print(f\"True Negatives:  {cm[0,0]:,}\")\n",
    "print(f\"False Positives: {cm[0,1]:,}\")\n",
    "print(f\"False Negatives: {cm[1,0]:,}\")\n",
    "print(f\"True Positives:  {cm[1,1]:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making third DTL with new hyperparameters\n",
    "### Hyperparameters reccomended by GPT \n",
    "Prompt : reccomend hyperparameters for a 7 million x 116 matrix for a DTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING SCORES\n",
      "model accuracy:  0.9890408958130477\n",
      "model precision:  0.9815619157198332\n",
      "model recall:  0.9968062317429406\n",
      "model f1 score:  0.9891253411918164\n",
      "\n",
      " TRAINING SCORES\n",
      "model accuracy:  0.9887268743914314\n",
      "model precision:  0.9806075549384785\n",
      "model recall:  0.9971738072054528\n",
      "model f1 score:  0.9888213001182804\n",
      "\n",
      "Confusion Matrix for TESTING:\n",
      "True Negatives:  100,777\n",
      "False Positives: 1,923\n",
      "False Negatives: 328\n",
      "True Positives:  102,372\n"
     ]
    }
   ],
   "source": [
    "dt_sklearn = DecisionTreeClassifier(\n",
    "    max_depth=16,                    # Tree depth\n",
    "    min_samples_split=12000,         # How many samples are required to split\n",
    "    min_samples_leaf=16000,           # Minimum samples per leaf\n",
    "    max_features='sqrt',            # Feature randomization\n",
    "    random_state=42,\n",
    "    class_weight='balanced'         \n",
    ")\n",
    "\n",
    "dt_sklearn.fit(X_train_sklearn, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_sklearn = dt_sklearn.predict(X_test_sklearn)\n",
    "y_pred_train_sklearn = dt_sklearn.predict(X_train_sklearn)\n",
    "\n",
    "# Calculate Test Scores\n",
    "test_accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
    "test_precision = precision_score(y_test, y_pred_sklearn)\n",
    "test_recall = recall_score(y_test, y_pred_sklearn)\n",
    "test_f1 = f1_score(y_test, y_pred_sklearn)\n",
    "\n",
    "# Calculate Training Scores\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train_sklearn)\n",
    "train_precision = precision_score(y_train, y_pred_train_sklearn)\n",
    "train_recall = recall_score(y_train, y_pred_train_sklearn)\n",
    "train_f1 = f1_score(y_train, y_pred_train_sklearn)\n",
    "\n",
    "print(\"TESTING SCORES\")\n",
    "print(\"model accuracy: \", test_accuracy)\n",
    "print(\"model precision: \", test_precision)\n",
    "print(\"model recall: \", test_recall)\n",
    "print(\"model f1 score: \", test_f1)\n",
    "\n",
    "print(\"\\n TRAINING SCORES\")\n",
    "print(\"model accuracy: \", train_accuracy)\n",
    "print(\"model precision: \", train_precision)\n",
    "print(\"model recall: \", train_recall)\n",
    "print(\"model f1 score: \", train_f1)\n",
    "\n",
    "print(\"\\nConfusion Matrix for TESTING:\")\n",
    "cm = confusion_matrix(y_test, y_pred_sklearn)\n",
    "print(f\"True Negatives:  {cm[0,0]:,}\")\n",
    "print(f\"False Positives: {cm[0,1]:,}\")\n",
    "print(f\"False Negatives: {cm[1,0]:,}\")\n",
    "print(f\"True Positives:  {cm[1,1]:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 (Unsupervised)\n",
    "Create a small stratified sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training rows: 821,600\n",
      "Sampled rows:       50,000\n",
      "Class proportion in sample:\n",
      "is_attack\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Small stratified sample for unsupervised model. This keeps things fast as we start analyzing our outputs\n",
    "from sklearn.model_selection import train_test_split\n",
    "MAX_SAMPLE = 50_000\n",
    "n = len(X_train_sklearn)\n",
    "if n > MAX_SAMPLE:\n",
    "    test_size = n - MAX_SAMPLE\n",
    "    X_unsup_small, _, y_unsup_small, _ = train_test_split(\n",
    "        X_train_sklearn, y_train,\n",
    "        test_size=test_size,\n",
    "        stratify=y_train,\n",
    "        random_state=42\n",
    ")\n",
    "else:\n",
    "    X_unsup_small = X_train_sklearn.copy()\n",
    "    y_unsup_small = y_train.copy()\n",
    "print(f\"Total training rows: {n:,}\")\n",
    "print(f\"Sampled rows:       {len(X_unsup_small):,}\")\n",
    "print(\"Class proportion in sample:\")\n",
    "print(y_unsup_small.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit PCA on just this small sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimensions: (50000, 116)\n",
      "PCA dimensions: (50000, 7)\n",
      "Explained variance ratio: 0.9567\n",
      "Number of components needed for 95% variance: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=42) #Keep 95% of variance\n",
    "X_pca = pca.fit_transform(X_unsup_small)\n",
    "\n",
    "print(f\"Original dimensions: {X_unsup_small.shape}\")\n",
    "print(f\"PCA dimensions: {X_pca.shape}\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"Number of components needed for 95% variance: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Clustering (k=2) on our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7193\n",
      "Training Precision: 0.9965\n",
      "Training Recall: 0.4401\n",
      "Training F1 Score: 0.6105\n",
      "---\n",
      "Test Accuracy: 0.7211\n",
      "Test Precision: 0.9968\n",
      "Test Recall: 0.4437\n",
      "Test F1 Score: 0.6140\n",
      "Test False Positives: 146\n",
      "Test False Negatives: 57134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Fit KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X_pca)\n",
    "\n",
    "# Training\n",
    "train_clusters = kmeans.predict(X_pca)\n",
    "\n",
    "# Map clusters to back to attack/benign\n",
    "mapping = {}\n",
    "for cluster in np.unique(train_clusters):\n",
    "    labels = y_unsup_small[train_clusters == cluster]\n",
    "    mapping[cluster] = labels.value_counts().idxmax()\n",
    "\n",
    "train_pred = np.array([mapping[c] for c in train_clusters])\n",
    "\n",
    "# Testing\n",
    "X_test_pca = pca.transform(X_test_sklearn)\n",
    "test_clusters = kmeans.predict(X_test_pca)\n",
    "test_pred = np.array([mapping[c] for c in test_clusters])\n",
    "\n",
    "# Compute Scores\n",
    "train_acc = accuracy_score(y_unsup_small, train_pred)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "train_precision = precision_score(y_unsup_small, train_pred)\n",
    "test_precision = precision_score(y_test, test_pred)\n",
    "train_recall = recall_score(y_unsup_small, train_pred)\n",
    "test_recall = recall_score(y_test, test_pred)\n",
    "train_f1 = f1_score(y_unsup_small, train_pred)\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(\"---\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Compute fp and fn for test set\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "fp = cm[0,1]\n",
    "fn = cm[1,0]\n",
    "print(f\"Test False Positives: {fp}\")\n",
    "print(f\"Test False Negatives: {fn}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
